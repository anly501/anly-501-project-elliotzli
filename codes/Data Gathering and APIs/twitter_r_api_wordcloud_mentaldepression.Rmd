```{r}
library("selectr")
library("rvest")
library("xml2")
library(rtweet) # for scraping tweets
library(wordcloud2) # for generating really cool looking wordclouds
library(tm) # for text minning
library(dplyr) # loads of fun stuff including piping
library(twitteR)
library(ROAuth)
library(jsonlite)
consumerKey=as.character('JKjzpgmwWJDhZ5spWwSG2ptBf')
consumerSecret=as.character('pwykbVIJYB9eTWNPIlX4Lafb5IFIATJGISX7nrlnof1xEl963x')
access_Token=as.character('1569710470554357760-UeAGnW9nY5VUOQpR38o14Lu0u1m01X')
access_Secret=as.character('Ax0HmTd1bqutfoYcTPJa7X7nE5ZkOI9x5TE9QEPefvM0l')

### Ensure the right URLs are stored to pull data

requestURL='https://api.twitter.com/oauth/request_token'
accessURL='https://api.twitter.com/oauth/access_token'
authURL='https://api.twitter.com/oauth/authorize'

setup_twitter_oauth(consumerKey,consumerSecret,access_Token,access_Secret)
Search2<-twitteR::searchTwitter("mental illness",n=5000, since="2022-01-01")
TweetsDF2<- twListToDF(Search2)
#(TweetsDF$text[1])
TweetsDF2$text <- gsub("[^[:alnum:][:blank:]?&/\\-]", "",TweetsDF2$text) # remove alphanumeric characters 
TweetsDF2$text <- gsub("https\\S*", "",TweetsDF2$text) # remove hyperlinks
#TweetsDF$text = gsub("(?!(#|@))[[:punct:]]", "", text, perl = sT) 
# remove all punctuations except # and @. 

#create a corpus to allow us clean the text column with tm
tweets.corpus2 <- Corpus(VectorSource(TweetsDF2$text))


tweets.corpus2 <- tweets.corpus2 %>%
  tm_map(removeNumbers) %>% # removes numbers from text
  tm_map(removePunctuation) %>% # removes punctuation from text
  tm_map(stripWhitespace) %>% # trims the text of whitespace
  tm_map(content_transformer(tolower)) %>% # convert text to lowercase
  tm_map(removeWords,stopwords("english")) %>% # remove stopwords
  tm_map(removeWords,stopwords("SMART")) # remove stopwords not removed from previous line

tdm2 <- TermDocumentMatrix(tweets.corpus2) %>% # create a term document matrix
      as.matrix()

words2 <- sort(rowSums(tdm2), decreasing = TRUE) # count all occurrences of each word and group them
df2 <- data.frame(word = names(words2), freq = words2) # convert it to a dataframe
head(df2) # visualize!

set.seed(1234) # for reproducibility
wcloud2 <- wordcloud2(df2,   # generate word cloud
                     size = 1.5,
                     color= 'random-dark', # set colors
                     #shape = 'pentagon',
                     rotateRatio = 0) #horizontal looks better, but what do you think?
wcloud2
```

