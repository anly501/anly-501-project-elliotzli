{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tweepy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load credentials:\n",
    "credentials = \"../../../Desktop/Georgetown/twitter-api-keys.json\"\n",
    "with open(credentials, \"r\") as keys:\n",
    "    api_tokens = json.load(keys)\n",
    "\n",
    "# Grab the API keys:\n",
    "API_KEY = api_tokens[\"consumer_key\"]\n",
    "API_SECRET = api_tokens[\"consumer_secret\"]\n",
    "BEARER_TOKEN = api_tokens[\"bearer_token\"]\n",
    "ACCESS_TOKEN = api_tokens[\"access_token\"]\n",
    "ACCESS_SECRET = api_tokens[\"access_token_secret\"]\n",
    "\n",
    "# Connect to the Twitter API:\n",
    "auth = tweepy.OAuthHandler(API_KEY, API_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "# Set the function parameters:\n",
    "query = \"drug abuse mental\"\n",
    "lang = \"en\"\n",
    "tweet_mode = \"extended\"\n",
    "count = 1000\n",
    "tweet_limit = 5000\n",
    "\n",
    "# Define the scraping function:\n",
    "def tweet_scraper(query=None, lang=\"en\", tweet_mode=\"extended\", count=100, tweet_limit=5000):\n",
    "    \"\"\"\n",
    "    This function takes Tweepy search_tweets parameters as arguments and returns a Pandas\n",
    "    dataframe containing tweet data.\n",
    "\n",
    "    :param query: a keyword search phrase (string)\n",
    "    :param lang: limit results by language (default: English)\n",
    "    :param tweet_mode: choose whether to extend tweets to full 280 characters.\n",
    "    :param count: the number of tweets to return per page (default: 100; max: 100)\n",
    "    :param tweet_limit: the maximum number of tweets to return (default: 1000).\n",
    "    \"\"\"\n",
    "\n",
    "    # Data dictionary for collecting results:\n",
    "    data = {\n",
    "        \"user_id\": [], \n",
    "        \"screen_name\": [],\n",
    "        \"name\": [],\n",
    "        \"verified\": [],\n",
    "        \"id\": [],\n",
    "        \"created_at\": [],\n",
    "        \"full_text\": [],\n",
    "        \"retweet_count\": [],\n",
    "        \"favorite_count\": [],\n",
    "        \"hashtags\": [],\n",
    "        \"user_mentions\": [],\n",
    "        \"in_reply_to_user_id\": [],\n",
    "        \"in_reply_to_screen_name\": [],\n",
    "        \"is_quote_status\": [],\n",
    "        \"is_retweet\": [], # we will have to build this parameter ourselves; see below\n",
    "        \"retweet_og_id\": [], # the ID of the original retweeted tweet\n",
    "        \"retweet_og_author_id\": [], # the original author ID of a retweeted tweet\n",
    "        \"retweet_og_author_screen_name\": [], # the original author screen name of a retweeted tweet\n",
    "        \"retweet_og_author_name\": [], # the original author's name of a retweeted tweet\n",
    "        \"retweet_og_date\": [], # the date of the original tweet\n",
    "        \"retweet_og_full_text\": [], # OG full text of the retweet\n",
    "        \"retweet_og_retweet_count\": [], # OG retweet count\n",
    "        \"retweet_og_favorite_count\": [] # OG favorite count\n",
    "    }\n",
    "\n",
    "    # Search the tweets as we've already done, but this time, plug in the paremeter values\n",
    "    # from the function arguments:\n",
    "\n",
    "    for tweet in tweepy.Cursor(api.search_tweets, q=query, tweet_mode=tweet_mode, count=count).items(tweet_limit):\n",
    "        # User ID:\n",
    "        data[\"user_id\"].append(tweet.user.id)\n",
    "        # Screen name:\n",
    "        data[\"screen_name\"].append(tweet.user.screen_name)\n",
    "        # Name:\n",
    "        data[\"name\"].append(tweet.user.name)\n",
    "        # verified status:\n",
    "        data[\"verified\"].append(tweet.user.verified)\n",
    "\n",
    "        # Tweet ID:\n",
    "        data[\"id\"].append(tweet.id)\n",
    "        # Date:\n",
    "        data[\"created_at\"].append(tweet.created_at)\n",
    "        # Full text of tweet:\n",
    "        data[\"full_text\"].append(tweet.full_text)\n",
    "        # Get retweet count:\n",
    "        data[\"retweet_count\"].append(tweet.retweet_count)\n",
    "        # Get favorite count:\n",
    "        data[\"favorite_count\"].append(tweet.favorite_count)\n",
    "        \n",
    "        # Get hashtags:\n",
    "        hashtags = []\n",
    "        try:\n",
    "            for hashtag in tweet.entities[\"hashtags\"]:\n",
    "                hashtags.append(hashtag[\"text\"])\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        if len(hashtags) == 0:\n",
    "            data[\"hashtags\"].append(np.nan)\n",
    "        else:\n",
    "            data[\"hashtags\"].append(hashtags)\n",
    "\n",
    "        # Get user mentions:\n",
    "        mentions = []\n",
    "        try:\n",
    "            for mention in tweet.entities[\"user_mentions\"]:\n",
    "                mentions.append(mention[\"screen_name\"])\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        if len(mentions) == 0:\n",
    "            data[\"user_mentions\"].append(np.nan)\n",
    "        else:\n",
    "            data[\"user_mentions\"].append(mentions)\n",
    "\n",
    "        # In reply to user id:\n",
    "        data[\"in_reply_to_user_id\"].append(tweet.in_reply_to_user_id)\n",
    "        # In reply to user screen name:\n",
    "        data[\"in_reply_to_screen_name\"].append(tweet.in_reply_to_screen_name)\n",
    "        # Check if quote status:\n",
    "        data[\"is_quote_status\"].append(tweet.is_quote_status)\n",
    "\n",
    "        # Check retweeted status:\n",
    "        if \"retweeted_status\" in tweet._json.keys():\n",
    "            # Then it is a retweet:\n",
    "            data[\"is_retweet\"].append(True)\n",
    "            # Get OG tweet id:\n",
    "            data[\"retweet_og_id\"].append(tweet.retweeted_status.id)\n",
    "            # Get OG author ID:\n",
    "            data[\"retweet_og_author_id\"].append(tweet.retweeted_status.user.id)\n",
    "            # Get OG author screen name:\n",
    "            data[\"retweet_og_author_screen_name\"].append(tweet.retweeted_status.user.screen_name)\n",
    "            # Get OG author name:\n",
    "            data[\"retweet_og_author_name\"].append(tweet.retweeted_status.user.name)\n",
    "            # Get date of OG tweet:\n",
    "            data[\"retweet_og_date\"].append(tweet.retweeted_status.created_at)\n",
    "            # Get OG full text:\n",
    "            data[\"retweet_og_full_text\"].append(tweet.retweeted_status.full_text)\n",
    "            # Get OG retweet count:\n",
    "            data[\"retweet_og_retweet_count\"].append(tweet.retweeted_status.retweet_count)\n",
    "            # Get OG favorite count:\n",
    "            data[\"retweet_og_favorite_count\"].append(tweet.retweeted_status.favorite_count)\n",
    "        else:\n",
    "            data[\"is_retweet\"].append(False)\n",
    "            data[\"retweet_og_id\"].append(np.nan)\n",
    "            data[\"retweet_og_author_id\"].append(np.nan)\n",
    "            data[\"retweet_og_author_screen_name\"].append(np.nan)\n",
    "            data[\"retweet_og_author_name\"].append(np.nan)\n",
    "            data[\"retweet_og_date\"].append(np.nan)\n",
    "            data[\"retweet_og_full_text\"].append(np.nan)\n",
    "            data[\"retweet_og_retweet_count\"].append(np.nan)\n",
    "            data[\"retweet_og_favorite_count\"].append(np.nan)\n",
    "\n",
    "    # Save to Pandas dataframe:\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Call the function and save results:\n",
    "df = tweet_scraper(query=query, lang=lang, tweet_mode=tweet_mode, count=count, tweet_limit=tweet_limit)\n",
    "\n",
    "# Save our results:\n",
    "df.to_json('drug abuse mental.json')\n",
    "\n",
    "# Let's create a function that cleans up the lists:\n",
    "def list_cleaner(list_object):\n",
    "    \"\"\"\n",
    "    This function takes one argument: list_object, which is list.\n",
    "    \"\"\"\n",
    "\n",
    "    # Let's try to join the list. Note that we nest the join in a Try/Except\n",
    "    # pattern. This is because not all Tweets contain either hashtags or user mentions.\n",
    "    # In this case, they simply have a NaN missing value. This will throw an error if \n",
    "    # not dealt with:\n",
    "\n",
    "    try:\n",
    "        output = \",\".join(list_object)\n",
    "    except Exception:\n",
    "        output = list_object\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Fix hashtags list:\n",
    "df[\"hashtags\"] = df[\"hashtags\"].apply(list_cleaner)\n",
    "\n",
    "# Fix mentions list:\n",
    "df[\"user_mentions\"] = df[\"user_mentions\"].apply(list_cleaner)\n",
    "\n",
    "df.to_csv(\"drug abuse mental.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ANLY501')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b99509343f58b5238b82254d4f767c9c788e2a2d44c001d79838f3f64bcef43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
